---
eval: false
---


# Census Data Extraction Pipeline: Documentation & Workflow

The following workflow demonstrates a reproducible method for extracting, cleaning, and calculating demographic indicators for counties using the US Census API.

This approach builds upon the core concepts and functions from Kyle Walker, the developer of `tidycensus` , and his documented online book, "Analyzing US Census Data". 


## The Motivation: "Don't Repeat Yourself"

In previous iterations of this work, I found myself constantly violating a core tenet of programming: **DRY (Don't Repeat Yourself).**

I would write a script to fetch Population data, then copy-paste that entire block to fetch Housing data, and copy-paste it again for Income data. I'd get lost in the variable table codes and in interpreting the raw data outputs from `get_acs().` The result was a script cluttered with repetitive logic. If I decided to change how I calculated a percentage or handled a missing value, I had to hunt down and fix it in five different places.

Maybe I'm just really bad at utilizing the existing powers and processes captured in `tidycensus().` 

Or maybe this could be a future development to embed in `tidycensus()` ? 



Either way, here it is...

Instead of writing repetitive code for every subject (Housing, Income, Population), we created a **custom "topic-based" pipeline. ** The pipeline abstracts logic into a standardized process that loops through metadata files: handling the heavy lifting automatically, consistently, and all in one place.

Primary Resource: [Walker Data: Analyzing US Census Data](https://walker-data.com/census-r/index.html)





------------------


## Setup: Project Scope and API Configuration

To interact with the Census Bureau's API, we use the `tidycensus` package. 
This requires a **valid API key**.

  * **Prerequisites:** You must request a free key from **http://api.census.gov/data/key_signup.html.**

  * **Security Note:** We use the config package to store the API key securely, rather than hard-coding it into the script.



We bring in other required libraries, and we also define our project scope and global variables used throughout.

By setting the state, target counties, and years in the global environment, we ensure consistent querying across all topics.



```{r}

library(tidycensus)
library(tidyr)
library(dplyr)
library(stringr)
library(purrr)
library(dplyr)
library(here)
library(config)

## these options below a) forces R to print full decimals 
###-- without defaulting to scientific notation
###-- and b) caches tigris data for quicker uploads
options(scipen = 99999, tigris_use_cache = TRUE)

## after safely storing your key in a .config file, 
###-- read it in like this
census_key <- config::get("census_key")

## , then you can use that variable to set the key:
census_api_key(census_key, overwrite = TRUE)

## set global variables
state_code   <- "MT"
counties <- c("Lewis and Clark", "Jefferson", "Broadwater", "Powell", "Meagher")
target_years <- c(2013, 2018, 2023)


```





## Setup: Creating the Variable Maps


Before we can fetch data, we need to tell R exactly what to fetch and how to treat it. Instead of hard-coding Census variables (like DP05_0001E) deeply into our scripts, we define them in "**Variable Map**" files.


These are CSV files that act as a "**Data Dictionary**." 

They define:

  * **label:** The human-readable name for your chart (e.g., "Population Under 5").

  * **variable:** The specific US Census code.

  * **stat_type:** Instructions for the calculator (is it a count, a currency, or a pre-calculated percent?).

  * **denominator:** Which variable acts as the "Total" for calculating percentages (e.g., Total Population).


You can create these CSVs using `tribble()` in R and save them to a directory. For example, I stored all of mine in a directory called "**variable_maps/**" 

You can call this directory and it's sub-files however you want to. You can change the names of the variables. But note that the rest of the script below is based specifically around these column keys. 


Here is a small example of how a variable map .csv is created and structured for the topic "Population"


```{r}


pop_ref_data <- tribble(
  ~label,                          ~variable,       ~stat_type,  ~denominator,    ~category,
  
  # --- BASIC COUNTS ---
  "Total Population",              "B01003_001",    "count",     NA,              "Population",
  "Median Age",                    "B01002_001",    "number",    NA,              "Population",
  
  # --- AGE GROUPS  ---
  "Pop Under 5 Years",             "S0101_C01_002", "count",     "S0101_C01_001", "Population",
  "Pop 5 to 17 Years",             "S0101_C01_003", "count",     "S0101_C01_001", "Population", 
  "Pop 18 to 24 Years",            "S0101_C01_004", "count",     "S0101_C01_001", "Population", 
  "Pop 65 Years and Over",         "S0101_C01_030", "count",     "S0101_C01_001", "Population", 

  # --- DENOMINATORS ---
  "Total Pop (Denom)",             "B01003_001",    "denom",     NA,              "Population",
  "Total Pop (Age Denom)",         "S0101_C01_001", "denom",     NA,              "Population"
)

# Save this variable map df to your directory
write_csv(pop_ref_data, here("variable_maps/population_vars_map.csv"))


```



-------------


## The Core Logic: Fetching "mapped" ACS Census Data

The standard `get_acs()` function is powerful but returns raw data. 

For a dashboard or report, we need more than just counts; it is super helpful to also return much needed context (human-readable table ID labels, general categories, meta-data on the type of estimate it is, what denominator or "universe" is used to calculate it, etc...).

Enter... custom function: `get_labeled_acs()`


### How it works:

  * **Splits Requests:** It separates variables into batches (Profile DP, Subject S, and Base B) to prevent API errors, as different table types cannot always be requested together.

  * **Iterates Over Years:** It automatically loops through the years defined in our setup (e.g., 2013, 2018, 2023).

  * **Joins Metadata:** Crucially, it merges the API results with our "Variable Maps" (CSVs). This attaches the human-readable labels (e.g., "Total Population") and calculation instructions (e.g., "Denominator is DP05_0001") directly to the data.
  

**`get_labeld_acs()`** function:   
  
```{r}
#| code-fold: true


get_labeled_acs <- function(ref_table, counties, state = "MT", years = target_years, survey_type = "acs5", 
                            geo_level = "county") {
  
  # 1. Split variables by type to create batches
  vars_dp <- ref_table %>% filter(str_starts(variable, "DP")) %>% pull(variable)
  vars_s  <- ref_table %>% filter(str_starts(variable, "S")) %>% pull(variable)
  vars_b  <- ref_table %>% filter(!str_starts(variable, "DP") & !str_starts(variable, "S")) %>% pull(variable)
  
  # 2. Iterate through years
  map_dfr(years, function(y) {
    message(paste(">>> Fetching data for", y, "..."))
    results_list <- list()
    
    # --- First batch: detailed table variables (`B` prefix) ---
    if (length(vars_b) > 0) {
      tryCatch({ 
        results_list[["B"]] <- get_acs(
          geography   = geo_level, 
          state       = state, 
          county      = counties, 
          year        = y, 
          survey      = survey_type,
          variables   = vars_b, 
          output      = "tidy", 
          cache_table = TRUE, 
          show_call   = FALSE
        ) 
      }, error = function(e) message(paste("   [!] B-Table batch failed for", y, ":", e$message)))
    }
    
    # --- Second batch: data profile variables (`DP` prefix) ---
    if (length(vars_dp) > 0) {
      tryCatch({ 
        results_list[["DP"]] <- get_acs(
          geography   = geo_level, 
          state       = state, 
          county      = counties, 
          year        = y, 
          survey      = survey_type,
          variables   = vars_dp, 
          output      = "tidy", 
          cache_table = TRUE, 
          show_call   = FALSE
        ) 
      }, error = function(e) message(paste("   [!] DP-Table batch failed for", y, ":", e$message)))
    }
    
    # --- Thrid batch: subject table variables (`S` prefix) ---
    if (length(vars_s) > 0) {
      tryCatch({ 
        results_list[["S"]] <- get_acs(
          geography   = geo_level, 
          state       = state, 
          county      = counties, 
          year        = y, 
          survey      = survey_type,
          variables   = vars_s, 
          output      = "tidy", 
          cache_table = TRUE, 
          show_call   = FALSE
        ) 
      }, error = function(e) message(paste("   [!] S-Table batch failed for", y, ":", e$message)))
    }
    
    # --- SAFETY CHECK ---
    # If ALL batches failed, we can't continue for this year.
    if (length(results_list) == 0) {
      warning(paste("!!! All batches failed for year", y))
      return(NULL)
    }
    
    # Combine all successful data pulls
    combined_data <- bind_rows(results_list)

    # Create a grid of all Counties x all Variables in the map
    ##-- variables from failed batches still appear in the df (filled as NA)
    distinct_geos <- combined_data %>% distinct(GEOID, NAME)
    
    full_grid <- expand_grid(
      distinct_geos,
      variable = ref_table$variable
    )
    
    # Final Join and Clean
    full_grid %>%
      left_join(combined_data, by = c("GEOID", "NAME", "variable")) %>%
      mutate(year = y, join_id = str_remove(variable, "E$")) %>%
      ##-- append the 'metadata' labels from our custom reference tables
      left_join(ref_table %>% mutate(join_id = str_remove(variable, "E$")), 
                by = "join_id", relationship = "many-to-many") %>%
      mutate(
        variable = coalesce(variable.y, variable.x),
        census_survey = "acs",
        survey_type = survey_type
        
        ) %>%
    
      select(
        GEOID, NAME, census_survey, survey_type,
        year, category, label, variable, estimate, 
        moe, stat_type, denominator
      )
  })
}


```
  
  

---------------------


## The Dynamic Percent Calculation Logic

Raw census counts (e.g., "250 people") are often less useful for comparison than percentages (e.g., "12% of the population").

Enter... custom function: `calc_acs_percents()` 


### How it works

  * **Performs a "self-join:** The dataframe looks up its own data. For every row marked as a "count" (e.g., Children in Poverty), it finds the corresponding "denominator" value (e.g., Total Children) for that specific county and year.

  * **Calculates the percent:** (Estimate / Denominator) * 100
  
  * **Ignores other data types:** this only selects the estimates that are true "counts," and ignores all others like rates, ratios, percents, or currency (e.g., "Unemployment Rate", "Median Income", "Percent of population in poverty") 


**`calc_acs_percents()`** function:   

```{r}
#| code-fold: true

calc_acs_percents <- function(df) {
  
  required_cols <- c("GEOID", "year", "variable", "estimate", "denominator", "stat_type")
  if (!all(required_cols %in% names(df))) {
    stop("Dataframe is missing required columns (denominator, stat_type, etc.)")
  }
  
  ##-- isolate just the values needed to serve as denominators
  denom_lookup <- df %>%
    select(GEOID, year, variable, denom_value = estimate) %>%
    distinct(GEOID, year, variable, .keep_all = TRUE) 
  
  ##-- join and calculate based on the 'denominator' code column
  df_calculated <- df %>%
    left_join(denom_lookup, 
              by = c("GEOID", "year", "denominator" = "variable")) %>%
    mutate(
      est_percent = case_when(
        ##-- if the estimate is a 'count' -> calculate the %
        stat_type == "count" & !is.na(denom_value) & denom_value > 0 ~ (estimate / denom_value) * 100,
        ##-- otherwise, don't... just return NA
        TRUE ~ NA_real_
      ),
      est_percent = round(est_percent, 2)
    )
  
  return(df_calculated)
}


```


-------------------


## Automation: The Master Processor

To avoid repeating code, we wrap the previous two steps into a single "Master Processor" 

Enter... custom function: `build_acs_topic()`


This function acts as the conductor of the final pipeline. It requires two specific inputs:

  * **Topic Name:** A label for the dataset (e.g., "Housing")
  
  * **Variable Map Filename:** The specific CSV file in the "**variable_maps/**" folder (or whatever you called it) that corresponds to that topic (e.g., housing_vars_map.csv). 
  
  
**Important:** The function relies on the "map_filename" to find the correct "instructions" for the API. It validates that the CSV exists and contains the necessary columns (stat_type, denominator) before attempting to fetch any data.



### How it works:

  * Validates the map file.

  * Runs `get_labeled_acs()` to pull the raw data
  
  * Runs `calc_acs_percents()` to calculate derived metrics
  
  * Returns a fully polished, ready-to-analyze dataset
  
  
By standardizing this process, you ensure that "Housing" data is treated with the exact same mathematical rigor as "Income" data, eliminating the risk of copy-paste errors between topics.


**`build_acs_topic()`** function:  

```{r}
#| code-fold: true


build_acs_topic <- function(topic_name, map_filename, 
                            counties, state, years, 
                            survey_type = "acs5", 
                            geo_level = "county") {
  
  full_path <- here("variable_maps", map_filename)
  message(paste("\n=== PROCESSING TOPIC:", topic_name, "(", survey_type, ") ==="))
  
  if (!file.exists(full_path)) {
    warning(paste("Map file not found:", full_path))
    return(NULL)
  }
  
  ref_table <- read_csv(full_path, show_col_types = FALSE)
  
  if (!all(c("stat_type", "denominator") %in% names(ref_table))) {
    stop("CSV is missing 'stat_type' or 'denominator' columns!")
  }
  
  ##-- fetch
  raw_data <- get_labeled_acs(ref_table, counties, state, years, survey_type, geo_level)
  if (is.null(raw_data)) return(NULL)
  message(paste("Columns returned by fetch:", paste(names(raw_data), collapse=", ")))
  
  ##-- final output
  clean_data <- calc_acs_percents(raw_data)
  message(paste("Successfully processed", nrow(clean_data), "rows."))
  return(clean_data)
}

```



----------------

## Putting it All Together: Running the Final Pipeline


This is the "Control Center" of the script. 

We first define a list of the topics we want to process. 

If we ever need to add a new category (e.g., "Transportation"), we simply create a new CSV map and add it here. 



```{r}

topic_list <- tribble(
          ~topic,   ~map_filename,
  "Population"  ,  "population_vars_map.csv",
  "Housing"     ,  "housing_vars_map.csv",
  "Income"      ,  "income_vars_map.csv",
  "Education"   ,  "education_vars_map.csv",
  "Employment"  ,  "employment_vars_map.csv",
  "Health"      ,  "health_vars_map.csv"
)


```




Then we simply run the code below, using `purrr::map2()` to iterate through this list, processing every topic automatically.



```{r}

##-- county-level data
cnty_census_data <- topic_list %>%
  mutate(data = map2(topic, map_filename, function(t, f) {
    build_acs_topic(t, f, counties, state_code, target_years)
  }))

##-- census tract data
tract_census_data <- topic_list %>%
  mutate(data = map2(topic, map_filename, function(t, f) {
    build_acs_topic(t, f, counties = lc_county, state_code, target_years, geo_level = "tract")
  }))


```



### The Final Outputs and Storage

The result of the pipeline is a **nested list** containing all our data. 

We can now:

  * Extract individual datasets (e.g., final_pop) for specific analysis.

  * Bind them together into a single combined dataframe

  * Export to CSV for future use like bringing them into a Shiny dashboard, Power BI, etc.



```{r}

# Create a named list for easy access
cnty_results_5yr  <- setNames(cnty_census_data$data, cnty_census_data$topic)
tract_results_5yr <- setNames(tract_census_data$data, tract_census_data$topic)

# Combine them all into a single df
cnty_census_5yr_df  <- bind_rows(cnty_results_5yr) 
tract_census_5yr_df <- bind_rows(tract_results_5yr) 

complete_census_df <- bind_rows(cnty_census_5yr_df, tract_census_5yr_df) %>%
##-- another custom function that calculates broader education categories like "BS or Higher"
  bind_education_summary() 

##-- you can also access/save them directly by name if you want
cnty_pop   <- cnty_results_5yr[["Population"]]
cnty_house <- cnty_results_5yr[["Housing"]]
cnty_inc   <- cnty_results_5yr[["Income"]]
cnty_edu   <- cnty_results_5yr[["Education"]]
cnty_emp   <- cnty_results_5yr[["Employment"]]
cnty_hlth  <- cnty_results_5yr[["Health"]]


```



```{r}

# Save it for later use, bring in the other applications, etc...

write.csv(
  complete_census_df, 
  file = here("_data/census_data/complete_census_df.csv"), 
  row.names = FALSE
)

```
